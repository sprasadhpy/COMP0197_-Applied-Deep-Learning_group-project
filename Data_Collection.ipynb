{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "SqpcsvA5ZjdN",
        "DYmlGPuvCyo6",
        "2UukUt9EDDDy",
        "YSdRoV9fV25o",
        "53Xy6q9pc51S",
        "6XIAt9-wqpWB",
        "7bEKEVjJYo2R",
        "YzzONarZvIXc",
        "JZ0Ny68JwQjd"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import datetime\n",
        "import torchvision\n",
        "import torch.nn as nn\n",
        "import os\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torchvision.transforms as transforms\n",
        "import requests\n",
        "import tarfile\n",
        "from torchvision.datasets import ImageFolder\n",
        "from torch.utils.data import ConcatDataset\n",
        "import zipfile\n",
        "from PIL import Image, ImageEnhance\n",
        "import torchvision.transforms.functional as TF\n",
        "\n",
        "import random\n",
        "\n",
        "torch.manual_seed(4)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A9LNh_j7rsoX",
        "outputId": "d9e40476-e64f-4d69-eba2-e987f5683d65"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7b093821d7d0>"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# define transformations that will be applied to all the datasets\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((120, 120)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),  # normalize to [-1, 1]\n",
        "    transforms.Lambda(lambda x: x / 2 + 0.5)  # normalize to [0, 1]\n",
        "])"
      ],
      "metadata": {
        "id": "fVobKx4FTajD"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# function to filter out images with a certain class\n",
        "def filter_classes(dataset, class_lbl):\n",
        "    indices = []\n",
        "    classes = dataset.classes\n",
        "    for i, (_, label) in enumerate(dataset):\n",
        "      if label in [classes.index(class_lbl)]:\n",
        "        indices.append(i)\n",
        "    return indices"
      ],
      "metadata": {
        "id": "PHKAFF0LVH5w"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Collect Data"
      ],
      "metadata": {
        "id": "dSQ1UVL2AWDS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Upload the Oxford-IIIT Pet Dataset"
      ],
      "metadata": {
        "id": "SqpcsvA5ZjdN"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "_cHdhRN68FJY",
        "outputId": "7b0ebbbe-c8ad-4f7d-d6a8-e65b1768742e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nraw_train_dataset = torchvision.datasets.OxfordIIITPet(root=\\'./data/oxford-pets\\', download=True)\\nraw_test_dataset = torchvision.datasets.OxfordIIITPet(root=\\'./data/oxford-pets\\', split=\\'test\\', download=True)\\n\\n# Extract breed names from file paths\\nbreeds = sorted(os.listdir(os.path.join(\\'./data/oxford-pets/oxford-iiit-pet\\', \\'images\\')))\\nnew_breeds = []\\nfor breed in breeds:\\n    # Remove numbers and \\'.jpg\\' from each breed name\\n    breed_name = \\'\\'.join(filter(lambda x: not x.isdigit(), breed))\\n    breed_name = breed_name.replace(\\'.jpg\\', \\'\\')\\n    breed_name = breed_name.replace(\\'_\\', \\' \\')\\n    breed_name = breed_name.replace(\\'.mat\\', \\'\\')\\n\\n    # Append \"yorkshire terrier 175.jpg\" to the new list\\n    new_breeds.append(breed_name)\\n\\nnew_breeds = list(set(new_breeds))  # Remove duplicates\\nnew_breeds.sort()\\n# Print the modified list\\n\\nfor breed in new_breeds:\\n    print(breed)\\n\\ncat_breeds = new_breeds[:12]\\ndog_breeds = new_breeds[12:]\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "'''\n",
        "raw_train_dataset = torchvision.datasets.OxfordIIITPet(root='./data/oxford-pets', download=True)\n",
        "raw_test_dataset = torchvision.datasets.OxfordIIITPet(root='./data/oxford-pets', split='test', download=True)\n",
        "\n",
        "# Extract breed names from file paths\n",
        "breeds = sorted(os.listdir(os.path.join('./data/oxford-pets/oxford-iiit-pet', 'images')))\n",
        "new_breeds = []\n",
        "for breed in breeds:\n",
        "    # Remove numbers and '.jpg' from each breed name\n",
        "    breed_name = ''.join(filter(lambda x: not x.isdigit(), breed))\n",
        "    breed_name = breed_name.replace('.jpg', '')\n",
        "    breed_name = breed_name.replace('_', ' ')\n",
        "    breed_name = breed_name.replace('.mat', '')\n",
        "\n",
        "    # Append \"yorkshire terrier 175.jpg\" to the new list\n",
        "    new_breeds.append(breed_name)\n",
        "\n",
        "new_breeds = list(set(new_breeds))  # Remove duplicates\n",
        "new_breeds.sort()\n",
        "# Print the modified list\n",
        "\n",
        "for breed in new_breeds:\n",
        "    print(breed)\n",
        "\n",
        "cat_breeds = new_breeds[:12]\n",
        "dog_breeds = new_breeds[12:]\n",
        "'''"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Extracting \"cats\" and \"dogs\" classes from CIFAR10:\n",
        "\n"
      ],
      "metadata": {
        "id": "DYmlGPuvCyo6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
        "#classes = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
        "\n",
        "# filter out images with cats and dogs only\n",
        "cat_indices = filter_classes(trainset, 'cat')\n",
        "dog_indices = filter_classes(trainset, \"dog\")\n",
        "\n",
        "# Create a subset containing only images with cats and dogs\n",
        "cat_subset = torch.utils.data.Subset(trainset, cat_indices)\n",
        "dog_subset = torch.utils.data.Subset(trainset, dog_indices)\n",
        "print(\"The CIFAR10 dataset downloaded successfully.\")\n",
        "\n",
        "#os.remove('./data/cifar-10-python.tar.gz')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l7_VwmtTBZvZ",
        "outputId": "55535d5b-f23d-437d-954b-65018a18782f"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 170498071/170498071 [00:04<00:00, 40215678.29it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/cifar-10-python.tar.gz to ./data\n",
            "The CIFAR10 dataset downloaded successfully.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Extracting \"dogs\" classes from Stanford dataset:\n"
      ],
      "metadata": {
        "id": "2UukUt9EDDDy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "_URL = 'http://vision.stanford.edu/aditya86/ImageNetDogs/images.tar'\n",
        "tar_file_path = './data/stanford-dogs.tar'\n",
        "\n",
        "response = requests.get(_URL)\n",
        "with open(tar_file_path, 'wb') as f:\n",
        "    f.write(response.content)\n",
        "\n",
        "extract_dir = './data/stanford-dogs'\n",
        "with tarfile.open(tar_file_path, 'r') as tar:\n",
        "    tar.extractall(extract_dir)\n",
        "\n",
        "os.remove(tar_file_path)\n",
        "\n",
        "print(\"The Stanford Dogs dataset downloaded and extracted successfully.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4sV9X0uAYh01",
        "outputId": "c3a92a52-6683-4af3-ea57-b36da89881f7"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The Stanford Dogs dataset downloaded and extracted successfully.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "stanford_dogs_dataset = ImageFolder(root='./data/stanford-dogs/Images', transform=transform)\n",
        "#classes = stanford_dogs_dataset.classes\n",
        "stanford_dogs_dataset.classes = 'dog'\n",
        "\n",
        "for i in range(len(stanford_dogs_dataset)):\n",
        "    _, label = stanford_dogs_dataset.samples[i]\n",
        "    stanford_dogs_dataset.samples[i] = stanford_dogs_dataset.samples[i][0], 'dog'"
      ],
      "metadata": {
        "id": "tZi2eOfhQRYM"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Concatenating dogs datasets"
      ],
      "metadata": {
        "id": "YSdRoV9fV25o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dogs = ConcatDataset([stanford_dogs_dataset, dog_subset])\n",
        "random_indices = torch.randperm(len(dogs))\n",
        "cats = torch.utils.data.Subset(dogs, random_indices)\n",
        "print(len(dogs))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x9fJs3b9V5h1",
        "outputId": "59b7b397-e81f-4b64-96dd-0eb93b1b51f1"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "25580\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# check dimensionality\n",
        "\n",
        "dataloader = DataLoader(dogs, batch_size=1, shuffle=False)\n",
        "dataset_size = len(dogs)\n",
        "print(\"Size of the concatenated dataset:\", dataset_size)\n",
        "\n",
        "for image, _ in dataloader:\n",
        "    sample_image_dimensions = image.shape[1:]  # Ignore batch dimension\n",
        "    break\n",
        "\n",
        "print(\"Dimensions of a sample image:\", sample_image_dimensions)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t65CxkTfYAHw",
        "outputId": "9787e66a-5a3f-4bdd-c67e-0bc21b2060a3"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Size of the concatenated dataset: 25580\n",
            "Dimensions of a sample image: torch.Size([3, 120, 120])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Extracting \"Cats\" class from kaggle set"
      ],
      "metadata": {
        "id": "53Xy6q9pc51S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "_URL = 'https://storage.googleapis.com/mledu-datasets/cats_and_dogs_filtered.zip'\n",
        "zip_file_path = './data/cats_and_dogs_filtered.zip'\n",
        "\n",
        "response = requests.get(_URL)\n",
        "with open(zip_file_path, 'wb') as f:\n",
        "    f.write(response.content)\n",
        "extract_dir = './data'\n",
        "with zipfile.ZipFile(zip_file_path, 'r') as zip_ref:\n",
        "    zip_ref.extractall(extract_dir)\n",
        "\n",
        "os.remove(zip_file_path)\n",
        "\n",
        "print(\"Cats Kaggle dataset downloaded and extracted successfully.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kdP0M2vqeaLp",
        "outputId": "3f63aaa0-75c7-4d48-ea9f-f1946cfe3f5c"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cats Kaggle dataset downloaded and extracted successfully.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cats_dogs_train = ImageFolder(root='./data/cats_and_dogs_filtered/train', transform=transform)\n",
        "\n",
        "cat_indices = filter_classes(cats_dogs_train, 'cats')\n",
        "\n",
        "cat_subset_2 = torch.utils.data.Subset(cats_dogs_train, cat_indices)\n",
        "print(len(cat_subset_2))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kzfAn1hviwv8",
        "outputId": "d23dc810-6fc2-44a4-fc89-5d5602d03a3d"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Extracting \"Cats\" class from Microsoft Cats&Dogs dataset"
      ],
      "metadata": {
        "id": "6XIAt9-wqpWB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "_URL = 'https://download.microsoft.com/download/3/E/1/3E1C3F21-ECDB-4869-8368-6DEBA77B919F/kagglecatsanddogs_5340.zip'\n",
        "zip_file_path = './data/kagglecatsanddogs.zip'\n",
        "\n",
        "response = requests.get(_URL)\n",
        "with open(zip_file_path, 'wb') as f:\n",
        "    f.write(response.content)\n",
        "extract_dir = './data'\n",
        "with zipfile.ZipFile(zip_file_path, 'r') as zip_ref:\n",
        "    zip_ref.extractall(extract_dir)\n",
        "\n",
        "os.remove(zip_file_path)\n",
        "\n",
        "print(\"Microsoft cats and dogs dataset downloaded and extracted successfully.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yn9ZadUY2SX1",
        "outputId": "5055bafe-7a30-4cbc-afee-a71c5eac1e2a"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Microsoft cats and dogs dataset downloaded and extracted successfully.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cats_dogs_train_3 = ImageFolder(root='./data/PetImages', transform=transform)\n",
        "classes = cats_dogs_train_3.classes\n",
        "\n",
        "cat_indices = []\n",
        "for idx in range(len(cats_dogs_train_3)):\n",
        "    try:\n",
        "        img, label = cats_dogs_train_3[idx]\n",
        "        if label == classes.index('Cat'):\n",
        "            cat_indices.append(idx)\n",
        "    except Exception as e:\n",
        "        print(f\"Skipped corrupted file at index {idx}: {e}\")\n",
        "\n",
        "\n",
        "# create a subset containing only cat images\n",
        "cat_subset_3 = torch.utils.data.Subset(cats_dogs_train_3, cat_indices)\n",
        "print(len(cat_subset_3))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DQ5_T54hntYF",
        "outputId": "d72183a3-b9e7-4dab-85f8-2b3c89d549be"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Skipped corrupted file at index 8790: cannot identify image file <_io.BufferedReader name='./data/PetImages/Cat/666.jpg'>\n",
            "Skipped corrupted file at index 14395: cannot identify image file <_io.BufferedReader name='./data/PetImages/Dog/11702.jpg'>\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/PIL/TiffImagePlugin.py:858: UserWarning: Truncated File Read\n",
            "  warnings.warn(str(msg))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "12499\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Concatenating cats datasets"
      ],
      "metadata": {
        "id": "7bEKEVjJYo2R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cats = ConcatDataset([cat_subset, cat_subset_2, cat_subset_3])\n",
        "random_indices = torch.randperm(len(cats))\n",
        "cats = torch.utils.data.Subset(cats, random_indices)\n",
        "print(len(cats))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PFp4jUEXYtGt",
        "outputId": "080a0397-2590-444a-a732-cb21bfb5ecf3"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "18499\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# check dimensionality\n",
        "\n",
        "dataloader = DataLoader(cats, batch_size=1, shuffle=False)\n",
        "dataset_size = len(cats)\n",
        "print(\"Size of the concatenated dataset:\", dataset_size)\n",
        "for image, _ in dataloader:\n",
        "    sample_image_dimensions = image.shape[1:]  # Ignore batch dimension\n",
        "    break\n",
        "\n",
        "print(\"Dimensions of a sample image:\", sample_image_dimensions)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fpenq4PzrI7K",
        "outputId": "95a25d5c-15c7-4c63-b68c-476573c3267f"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Size of the concatenated dataset: 18499\n",
            "Dimensions of a sample image: torch.Size([3, 120, 120])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Concatenating cats and dogs datasets and ensure equal sizes"
      ],
      "metadata": {
        "id": "YzzONarZvIXc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dogs_reduced = torch.utils.data.Subset(dogs, torch.randperm(len(cats)))\n",
        "pets = ConcatDataset([cats, dogs_reduced])\n",
        "pets = torch.utils.data.Subset(pets,torch.randperm(len(pets)))\n",
        "\n",
        "print(len(pets))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c0gzFFLWvSBY",
        "outputId": "e71e17f0-b5e9-4946-d85e-4dd16cb01f3f"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "36998\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Saving data for pretraining in a separate folder"
      ],
      "metadata": {
        "id": "JZ0Ny68JwQjd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "output_dir = \"./pets_images\"\n",
        "os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "for i, (image, label) in enumerate(pets):\n",
        "    image_pil = transforms.ToPILImage()(image)\n",
        "    filename = f\"image_{i}.jpg\"\n",
        "    image_path = os.path.join(output_dir, filename)\n",
        "    image_pil.save(image_path)\n",
        "\n",
        "print(\"Images saved successfully.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B0RfJQYYv5ly",
        "outputId": "336a8167-8873-4046-a446-bc5b7ba39dc8"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Images saved successfully.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Implement Transformation Functions"
      ],
      "metadata": {
        "id": "Bc0XZ_NRAtYA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Rotation Function"
      ],
      "metadata": {
        "id": "D6BBlsOJpgGa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# function to randomly rotate an image and return the rotation degree\n",
        "def rotate_image(image):\n",
        "    degrees = [0, 90, 180, 270]\n",
        "    deg = random.choice(degrees)\n",
        "    rotated_image = image.rotate(deg, expand=True)\n",
        "    return rotated_image, deg\n"
      ],
      "metadata": {
        "id": "nm4a7xwnpfqz"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# run if you want to apply rotation\n",
        "\n",
        "'''\n",
        "output_dir = \"./rotated_pets_images\"\n",
        "os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "for i, (image, label) in enumerate(pets):\n",
        "    image_pil = transforms.ToPILImage()(image)\n",
        "    rotated_image, degree = rotate_image(image_pil)\n",
        "\n",
        "    # save the image with a unique filename including the rotation degree\n",
        "    filename = f\"image_{i}_{degree}deg.jpg\"\n",
        "    image_path = os.path.join(output_dir, filename)\n",
        "    rotated_image.save(image_path)\n",
        "\n",
        "print(\"Images saved successfully with labels indicating rotation degree.\")\n",
        "'''"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "id": "mlgxEpUzGuah",
        "outputId": "b993fefb-1307-41fc-c1cd-b586997e34b3"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\noutput_dir = \"./rotated_pets_images\"\\nos.makedirs(output_dir, exist_ok=True)\\n\\nfor i, (image, label) in enumerate(pets):\\n    image_pil = transforms.ToPILImage()(image)\\n    rotated_image, degree = rotate_image(image_pil)\\n\\n    # save the image with a unique filename including the rotation degree\\n    filename = f\"image_{i}_{degree}deg.jpg\"\\n    image_path = os.path.join(output_dir, filename)\\n    rotated_image.save(image_path)\\n\\nprint(\"Images saved successfully with labels indicating rotation degree.\")\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Color Distortion function"
      ],
      "metadata": {
        "id": "wgdqQ6TLBim1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# function to apply color distortion to an image and return the distorted image\n",
        "def distort_color(image):\n",
        "    color_jitter = transforms.ColorJitter(\n",
        "        brightness=0.5,\n",
        "        contrast=0.5,\n",
        "        saturation=0.5,\n",
        "        hue=0.1\n",
        "    )\n",
        "\n",
        "    distorted_image = color_jitter(image)\n",
        "    return distorted_image\n"
      ],
      "metadata": {
        "id": "HPJFJAooBjY6"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# run if you want to apply color jittering\n",
        "'''\n",
        "output_dir = \"./distorted_pets_images\"\n",
        "os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "for i, (image, label) in enumerate(pets):\n",
        "    image_pil = transforms.ToPILImage()(image)\n",
        "    distorted_image = distort_color(image_pil)\n",
        "\n",
        "    # save the distorted image\n",
        "    filename = f\"image_{i}_distorted.jpg\"\n",
        "    image_path = os.path.join(output_dir, filename)\n",
        "    distorted_image.save(image_path)\n",
        "\n",
        "print(\"Images saved successfully with color distortion.\")\n",
        "'''"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "id": "VkEw-NmdG9Mv",
        "outputId": "81ccf253-041d-4df4-a087-e1dc27b11065"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\noutput_dir = \"./distorted_pets_images\"\\nos.makedirs(output_dir, exist_ok=True)\\n\\nfor i, (image, label) in enumerate(pets):\\n    image_pil = transforms.ToPILImage()(image)\\n    distorted_image = distort_color(image_pil)\\n\\n    # save the distorted image\\n    filename = f\"image_{i}_distorted.jpg\"\\n    image_path = os.path.join(output_dir, filename)\\n    distorted_image.save(image_path)\\n\\nprint(\"Images saved successfully with color distortion.\")\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Greyscale Function"
      ],
      "metadata": {
        "id": "fY-uyTtMHgOh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# function to apply random greyscale transformation to an image\n",
        "def greyscale(image):\n",
        "    grayscale_transform = transforms.RandomGrayscale(p=0.2)\n",
        "    greyscale_image = grayscale_transform(image)\n",
        "\n",
        "    return greyscale_image"
      ],
      "metadata": {
        "id": "A5mNuDdcBjoD"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# run if you want to apply greyscaling\n",
        "'''\n",
        "output_dir = \"./greyscaled_pets_images\"\n",
        "os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "for i, (image, label) in enumerate(pets):\n",
        "    image_pil = transforms.ToPILImage()(image)\n",
        "    distorted_image = greyscale(image_pil)\n",
        "\n",
        "    # save the distorted image\n",
        "    filename = f\"image_{i}_greyscaled.jpg\"\n",
        "    image_path = os.path.join(output_dir, filename)\n",
        "    distorted_image.save(image_path)\n",
        "\n",
        "print(\"Images saved successfully with greyscale.\")\n",
        "'''"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        },
        "id": "K74MuU90Bjzo",
        "outputId": "caa1e8bb-fea5-483e-bb90-6e89b3b1517d"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\noutput_dir = \"./greyscaled_pets_images\"\\nos.makedirs(output_dir, exist_ok=True)\\n\\nfor i, (image, label) in enumerate(pets):\\n    image_pil = transforms.ToPILImage()(image)\\n    distorted_image = greyscale(image_pil)\\n\\n    # save the distorted image\\n    filename = f\"image_{i}_greyscaled.jpg\"\\n    image_path = os.path.join(output_dir, filename)\\n    distorted_image.save(image_path)\\n\\nprint(\"Images saved successfully with greyscale.\")\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Masking Function"
      ],
      "metadata": {
        "id": "LRq0JzL5Rfvg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def mask_image(image, mask_percentage):\n",
        "\n",
        "    rows, cols = image.shape[1:]\n",
        "    rows_to_mask = int(rows * mask_percentage / 100)\n",
        "    cols_to_mask = int(cols * mask_percentage / 100)\n",
        "\n",
        "    top_left_row = random.randint(0, rows - rows_to_mask)\n",
        "    top_left_col = random.randint(0, cols - cols_to_mask)\n",
        "\n",
        "    image[:, top_left_row:top_left_row + rows_to_mask, top_left_col:top_left_col + cols_to_mask] = 0.5\n",
        "\n",
        "    return image"
      ],
      "metadata": {
        "id": "lCZMPzBERiSb"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# run if you want to apply masking\n",
        "'''\n",
        "output_dir = \"./masked_pets_images\"\n",
        "os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "for i, (image, label) in enumerate(pets):\n",
        "    image_pil = transforms.ToPILImage()(image)\n",
        "    masked_image = mask_image(image, 75)\n",
        "    masked_image = transforms.ToPILImage()(masked_image)\n",
        "    # save the masked image\n",
        "    filename = f\"image_{i}_masked.jpg\"\n",
        "    image_path = os.path.join(output_dir, filename)\n",
        "    masked_image.save(image_path)\n",
        "\n",
        "print(\"Images saved successfully with greyscale.\")\n",
        "'''"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-leqgsevRx5O",
        "outputId": "c64a981f-3f81-4e6c-e528-68e243047d2e"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Images saved successfully with greyscale.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Apply all transformations"
      ],
      "metadata": {
        "id": "ihysyr24NMZU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "output_dir = \"./transformed_pets_images\"\n",
        "os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "for i, (image, label) in enumerate(pets):\n",
        "    image_pil = transforms.ToPILImage()(image)\n",
        "    im = greyscale(image_pil)\n",
        "    im = distort_color(im)\n",
        "    im, rotation = rotate_image(im)\n",
        "\n",
        "    # save the distorted image\n",
        "    filename = f\"image_{i}_transformed.jpg\"\n",
        "    image_path = os.path.join(output_dir, filename)\n",
        "    im.save(image_path)\n",
        "\n",
        "print(\"Transformed images saved successfully.\")\n",
        "'''"
      ],
      "metadata": {
        "id": "pYRM2akyNSQ9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "outputId": "7ee233ee-ed52-4185-acb6-bd87679932ed"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\noutput_dir = \"./transformed_pets_images\"\\nos.makedirs(output_dir, exist_ok=True)\\n\\nfor i, (image, label) in enumerate(pets):\\n    image_pil = transforms.ToPILImage()(image)\\n    im = greyscale(image_pil)\\n    im = distort_color(im)\\n    im, rotation = rotate_image(im)\\n\\n    # save the distorted image\\n    filename = f\"image_{i}_transformed.jpg\"\\n    image_path = os.path.join(output_dir, filename)\\n    im.save(image_path)\\n\\nprint(\"Transformed images saved successfully.\")\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    }
  ]
}