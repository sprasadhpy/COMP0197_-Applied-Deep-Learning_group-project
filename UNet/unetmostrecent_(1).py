# -*- coding: utf-8 -*-
"""UNETmostrecent (1).ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/13VO21Ou6nrThbrdd2UkL5EUdvMWf9h4I
"""

import torch
import datetime
import torchvision
import torch.nn as nn
import os
from torch.utils.data import Dataset, DataLoader
import torchvision.transforms as transforms
import requests
import tarfile
from torchvision.datasets import ImageFolder
from torch.utils.data import ConcatDataset
import zipfile
from PIL import Image, ImageEnhance
import torchvision.transforms.functional as TF
from torchvision import datasets, transforms
import torch.optim as optim
from tqdm import tqdm
import random
import torch

import torch.nn as nn
import torch.nn.functional as F
torch.manual_seed(4)
import torchvision.transforms as T
import matplotlib.pyplot as plt
t2img = T.ToPILImage()
img2t = T.ToTensor()



from google.colab import drive
drive.mount('/content/drive', force_remount=True)
folder_path = "/content/drive/My Drive/ADL"

# Assuming folder_path is already set to the current working directory
with zipfile.ZipFile(f"{folder_path}/pets_images_final.zip", 'r') as zip_ref:
    zip_ref.extractall("/sample_data")
pretrain_data_path = '/sample_data/pets_images'

# List everything in /tmp
tmp_contents = os.listdir(pretrain_data_path)
print(tmp_contents[:10])
num_workers = os.cpu_count()
num_workers

transform = transforms.Compose([
    transforms.Resize((120, 120)),
    transforms.ToTensor(),
    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),  # normalize to [-1, 1]
    transforms.Lambda(lambda x: x / 2 + 0.5),  # normalize to [0, 1]
])

def greyscale(image):
    grayscale_transform = transforms.RandomGrayscale(p=0.2)
    imgs = []
    for i in range(image.shape[0]):
        im=transforms.ToPILImage()(image[i])
        greyscale_image = grayscale_transform(im)
        imgs.append(transform(greyscale_image).unsqueeze(0))

    return torch.cat(imgs,0)

def distort_color(image):
    color_jitter = transforms.ColorJitter(
        brightness=0.5,
        contrast=0.5,
        saturation=0.5,
        hue=0.1
    )
    imgs=[]
    for i in range(image.shape[0]):
        im=transforms.ToPILImage()(image[i])
        distorted_image = color_jitter(im)
        imgs.append(transform(distorted_image).unsqueeze(0))
    return torch.cat(imgs,0)

def mask_image(image, low_mask_percentage,high_mask_percentage):
    for i in range(image.shape[0]):
        mask_percentage=random.randint(low_mask_percentage,high_mask_percentage)
        rows, cols = image.shape[2:]
        rows_to_mask = int(rows * mask_percentage / 100)
        cols_to_mask = int(cols * mask_percentage / 100)

        top_left_row = random.randint(0, rows - rows_to_mask)
        top_left_col = random.randint(0, cols - cols_to_mask)

        image[i,:, top_left_row:top_left_row + rows_to_mask, top_left_col:top_left_col + cols_to_mask] = 0.5

    return image

distort=transforms.Compose([
    transforms.RandomChoice([lambda x: mask_image(x,5,25),greyscale,distort_color]),
])

device = "cuda" if torch.cuda.is_available() else "cpu"

print(f"Using device: {device}")

class CustomImageDataset(Dataset):
    """A custom dataset class for loading preprocessed and saved images."""

    def __init__(self, image_dir, transform=None):
        """
        Args:
            image_dir (string): Path to the directory with preprocessed images.
            transform (callable, optional): Optional transform to be applied
                on a sample.
        """
        self.image_dir = image_dir
        self.transform = transform
        self.image_paths = [os.path.join(image_dir, img_name) for img_name in os.listdir(image_dir)
                            if os.path.isfile(os.path.join(image_dir, img_name))]

    def __len__(self):
        """Returns the total number of samples in the dataset."""
        return len(self.image_paths)

    def __getitem__(self, idx):
        """
        Args:
            idx (int): Index of the sample to be fetched

        Returns:
            A tuple (image, label), where 'image' is the transformed image tensor,
            and 'label' could be a dummy value if not applicable.
        """
        img_path = self.image_paths[idx]
        image = Image.open(img_path).convert('RGB')  # Convert to RGB for consistency

        if self.transform:
            image = self.transform(image)

        label = 0
        return image

pre_training_data= CustomImageDataset(pretrain_data_path,transform=transform)
pre_train_dataloader = DataLoader(pre_training_data, batch_size=64, shuffle=True)
len(pre_train_dataloader)

class double_conv(nn.Module):
    """(conv => BN => ReLU) * 2"""

    def __init__(self, in_ch, out_ch):
        super(double_conv, self).__init__()
        self.conv = nn.Sequential(
            nn.Conv2d(in_ch, out_ch, 3, padding=1),
            nn.BatchNorm2d(out_ch),
            nn.ReLU(inplace=True),
            nn.Conv2d(out_ch, out_ch, 3, padding=1),
            nn.BatchNorm2d(out_ch),
            nn.ReLU(inplace=True),
        )

    def forward(self, x):
        x = self.conv(x)
        return x


class inconv(nn.Module):
    def __init__(self, in_ch, out_ch):
        super(inconv, self).__init__()
        self.conv = double_conv(in_ch, out_ch)

    def forward(self, x):
        x = self.conv(x)
        return x


class down(nn.Module):
    def __init__(self, in_ch, out_ch):
        super(down, self).__init__()
        self.mpconv = nn.Sequential(nn.MaxPool2d(2), double_conv(in_ch, out_ch))

    def forward(self, x):
        x = self.mpconv(x)
        return x


class up(nn.Module):
    def __init__(self, in_ch, out_ch, bilinear=True):
        super(up, self).__init__()

        if bilinear:
            self.up = nn.Upsample(scale_factor=2, mode="bilinear", align_corners=True)
        else:
            self.up = nn.ConvTranspose2d(in_ch // 2, in_ch // 2, 2, stride=2)

        self.conv = double_conv(in_ch, out_ch)

    def forward(self, x1, x2):
        x1 = self.up(x1)

        # input is CHW
        diffY = x2.size()[2] - x1.size()[2]
        diffX = x2.size()[3] - x1.size()[3]

        x1 = F.pad(x1, (diffX // 2, diffX - diffX // 2, diffY // 2, diffY - diffY // 2))

        x = torch.cat([x2, x1], dim=1)
        return self.conv(x)


class outconv(nn.Module):
    def __init__(self, in_ch, out_ch):
        super(outconv, self).__init__()
        self.conv = nn.Conv2d(in_ch, out_ch, 1)

    def forward(self, x):
        x = self.conv(x)
        return x


class UNet(nn.Module):
    def __init__(self, n_channels, n_classes):
        super(UNet, self).__init__()
        self.inc = inconv(n_channels, 64)
        self.down1 = down(64, 128)
        self.down2 = down(128, 256)
        self.down3 = down(256, 512)
        self.down4 = down(512, 512)
        self.up1 = up(1024, 256, False)
        self.up2 = up(512, 128, False)
        self.up3 = up(256, 64, False)
        self.up4 = up(128, 64, False)
        self.outc = outconv(64, n_classes)

    def forward(self, x):
        x1 = self.inc(x)
        x2 = self.down1(x1)
        x3 = self.down2(x2)
        x4 = self.down3(x3)
        x5 = self.down4(x4)
        x = self.up1(x5, x4)
        x = self.up2(x, x3)
        x = self.up3(x, x2)
        x = self.up4(x, x1)
        x = self.outc(x)
        return x

model = UNet(n_channels=3, n_classes=3).float().to(device)

def calculate_supervised_dice_score(predictions, ground_truth):
    """
    Calculate the supervised Dice score for labeled data.

    Args:
        predictions (torch.Tensor): Predictions for labeled data, with shape (batch_size, num_classes, height, width).
        ground_truth (torch.Tensor): Ground truth masks for labeled data, with shape (batch_size, num_classes, height, width).

    Returns:
        torch.Tensor: Supervised Dice score.
    """
    # Convert raw model outputs into probabilities within the range [0, 1] to ensure alignment with the ground truth masks
    predictions = torch.sigmoid(predictions)

    # Smoothing factor to prevent division by zero
    smooth = 1e-5

    # Compute the intersection and union
    intersection = torch.sum(ground_truth * predictions, dim=(1, 2, 3))
    cardinality = torch.sum(ground_truth, dim=(1, 2, 3)) + torch.sum(predictions, dim=(1, 2, 3))

    # Calculate the Dice score
    dice_score = 2 * (intersection + smooth) / (cardinality+ smooth)
    return dice_score.sum()


def calculate_supervised_iou_score(predictions, ground_truth):
    """
    Calculate the supervised IOU score for labeled data.

    Args:
        predictions (torch.Tensor): Predictions for labeled data, with shape (batch_size, num_classes, height, width).
        ground_truth (torch.Tensor): Ground truth masks for labeled data, with shape (batch_size, num_classes, height, width).

    Returns:
        torch.Tensor: Supervised IOU score.
    """
    # Convert raw model outputs into probabilities within the range [0, 1] to ensure alignment with the ground truth masks
    predictions = torch.sigmoid(predictions)

    # Smoothing factor to prevent division by zero
    smooth = 1e-5

    # Compute the intersection and union
    intersection = torch.sum(ground_truth * predictions, dim=(1, 2, 3))
    union = torch.sum(ground_truth, dim=(1, 2, 3)) + torch.sum(predictions, dim=(1, 2, 3)) -intersection

    # Calculate the IOU score
    iou_score = (intersection + smooth) / (union + smooth)

    return iou_score.sum()


def pretrain(net, criterion, optimizer, trainloader, epochs):
    trainloss=[]
    net.train().to(device)
    dl=[]
    iouscore=[]
    for epoch in range(epochs):
        print('Epoch', epoch+1)
        running_loss = 0.0
        dice=0.0
        total=0.0
        iou=0.0
        for i, data in tqdm(enumerate(trainloader, 0)):
            optimizer.zero_grad()
            inputs = data.to(device)
            inputs_distorted=distort(inputs).float().to(device)
            outputs = net(inputs_distorted)
            loss = criterion(outputs, inputs)
            loss.backward(retain_graph=False)
            dice+=calculate_supervised_dice_score(outputs,inputs).item()
            iou+=calculate_supervised_iou_score(outputs,inputs).item()
            optimizer.step()

            running_loss += loss.detach().item()
            total += inputs.size(0)
        trainloss.append(running_loss/total)
        iouscore.append(iou/total)
        dl.append(dice/total)
        print('[%d, %2d]   loss: %.5f Dice Score: %.5f IOU Score: %.5f'  %
                    (epoch + 1,epochs, trainloss[epoch],dl[epoch] ,iouscore[epoch]))
    return trainloss , dl , iouscore

criterion1 =  torch.nn.MSELoss().to(device)

optimizer = optim.AdamW(model.parameters(), lr=0.0001)
print(pre_train_dataloader)
mse , dlpt, iouscore = pretrain(model, criterion1, optimizer, pre_train_dataloader, 20)

print("Model's state_dict:")
for param_tensor in model.state_dict():
    print(param_tensor, "\t", model.state_dict()[param_tensor].size())

# Print optimizer's state_dict
print("Optimizer's state_dict:")
for var_name in optimizer.state_dict():
    print(var_name, "\t", optimizer.state_dict()[var_name])

model_path = os.path.join(folder_path, f'Unet_pretrained_2.pt')
torch.save(model.state_dict(), model_path)

def tensor_trimap(t):
    x =(t * 255.0 -1.0)
    x = x.to(torch.long)
    x = 255.0 * x + 1.0
    return x

transform = transforms.Compose([
    transforms.Resize((120, 120)),
    transforms.ToTensor(),
    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),  # normalize to [-1, 1]
    transforms.Lambda(lambda x: x / 2 + 0.5),  # normalize to [0, 1]
])
target_transform=transforms.Compose([
    transforms.Resize((120, 120),interpolation=transforms.InterpolationMode.NEAREST),
    transforms.ToTensor(),#transforms.Lambda(tensor_trimap)
    transforms.Lambda(lambda x: torch.nn.functional.one_hot((x*255).long() - 1,3).squeeze(0).permute(2,0,1))
])




training_data = torchvision.datasets.OxfordIIITPet(root='./data/oxford-pets', split='trainval',transform=transform,target_types="segmentation",target_transform=target_transform,download=True)
train_dataloader = DataLoader(training_data, batch_size=64, shuffle=True,num_workers=num_workers)




testing_data = torchvision.datasets.OxfordIIITPet(root='./data/oxford-pets', split='test',transform=transform,target_types="segmentation",target_transform=target_transform,download=True)
test_dataloader = DataLoader(testing_data, batch_size=3, shuffle=False,num_workers=num_workers)

(train_pets_inputs, train_pets_targets) = next(iter(train_dataloader))

print(train_pets_inputs.shape, train_pets_targets.shape)

pets_input_grid = torchvision.utils.make_grid(train_pets_inputs, nrow=8)
t2img(pets_input_grid)

pets_targets_grid = torchvision.utils.make_grid(train_pets_targets/1.0  , nrow=8)
t2img(pets_targets_grid)

def train(net, criterion, optimizer, trainloader, epochs):
    trainloss=[]
    dl=[]
    iouscore=[]
    net.train().to(device)
    for epoch in range(epochs):

        print('Epoch', epoch+1)
        running_loss = 0.0
        dice=0.0
        total=0.0
        iou=0.0
        acc=0.0
        for  batch_idx, data in tqdm(enumerate(trainloader, 0)):
            optimizer.zero_grad()
            inputs, labels = data
            inputs, labels = inputs.float().to(device), labels.float().to(device)
            outputs = net(inputs)





            loss = criterion(outputs, labels)

            loss.backward(retain_graph=False)


            dice+=calculate_supervised_dice_score(outputs,labels).item()
            iou+=calculate_supervised_iou_score(outputs,labels).item()
            acc+=torch.mean((torch.argmax(outputs,1)==torch.argmax(labels,1)).float(),dim=(1,2)).sum().item()
            optimizer.step()
            running_loss += loss.detach().item()
            total += inputs.size(0)
        dl.append(dice/total)
        iouscore.append(iou/total)
        print("accuracy:", acc / total)
        trainloss.append(running_loss/total)
        print('[%d, %2d]   loss: %.5f Dice Score: %.5f IOU Score: %.5f'  %
                    (epoch + 1,epochs, trainloss[epoch],dl[epoch] ,iouscore[epoch]))

    return trainloss , dl , iouscore

tl , dl,iou = train(model, criterion1, optimizer, train_dataloader, 50)

#tl , dl, iou = train(model, criterion1, optimizer, train_dataloader,50 )

model_path = os.path.join(folder_path, f'Unet_trained_2.pt')
torch.save(model.state_dict(), model_path)

def test(model,  test_data, epochs=20):
    testacc=[]
    ds=[]
    iouscore=[]
    model.eval().to(device)
    for epoch in range(epochs):
        print('Epoch',epoch+1)
        dice=0.0
        total=0.0
        acc=0.0
        iou=0.0
        with torch.no_grad():
            for batch_idx, data in tqdm(enumerate(test_data, 0)):
                inputs , labels = data
                #inputs,labels = inputs.to(device), labels.to(device)
                #print(labels.shape,'label')
                #print(inputs.shape,'input')
                #predictions = model(inputs)
                #print(predictions.shape,'pred')
                #print(predictions.shape,labels.shape)
                #pred = nn.Softmax(dim=1)(predictions)

                inputs,labels = inputs.to(device), labels.to(device)
                #print(labels.shape,'label')
                #print(inputs.shape,'input')

                predictions = model(inputs)



                #pred = nn.Softmax(dim=1)(predictions)

                #pred_labels = pred.argmax(dim=1)
                #print(pred_labels.shape)
                #pred_labels = pred_labels.unsqueeze(1)
                #print(pred_labels.shape)

                #pred_mask = pred_labels.to(torch.float)
                acc+=torch.mean((torch.argmax(predictions,1)==torch.argmax(labels,1)).float(),dim=(1,2)).sum().item()
                dice +=calculate_supervised_dice_score(predictions,labels).item()
                #acc += IoUMetric(pred, labels).detach().item()
                iou+=calculate_supervised_iou_score(predictions,labels).item()
                #pred_labels = predictions.argmax(dim=1)
                #print(pred_labels.shape)
                #pred_labels = pred_labels.unsqueeze(1)
                #print(pred_labels.shape)
                #pred_mask = pred_labels.to(torch.float)
                #print(pred_mask.shape)
                #dice+=calculate_supervised_dice_score(predictions,labels).item()
                total += inputs.size(0)




        ds.append(dice/total)
        iouscore.append(iou/total)
        testacc.append(acc/total)
        print('Testing : [%d, %2d]   Dice Score: %.5f IOU Score: %.5f Accuracy : %.5f ' %
                    (epoch + 1,epochs,   ds[epoch] ,iouscore[epoch],testacc[epoch]))
        if (epoch +1 == 1):
          fig = plt.figure(figsize=(10, 12))
          fig.suptitle('Segmentations', fontsize=12)

          fig.add_subplot(3, 1, 1)
          plt.imshow(t2img(torchvision.utils.make_grid(inputs, nrow=8)))
          plt.axis('off')
          plt.title("Images")

          fig.add_subplot(3, 1, 2)
          plt.imshow(t2img(torchvision.utils.make_grid(labels.float()/1.0 , nrow=8)))
          plt.axis('off')
          plt.title("Ground Truth Labels")

          fig.add_subplot(3, 1, 3)
          plt.imshow(t2img(torchvision.utils.make_grid(predictions, nrow=8)))
          plt.axis('off')
          plt.title("Predicted Labels")
    return

test(model,  test_dataloader, epochs=1)

